{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split as TTS\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.feature_selection import chi2, SelectKBest, f_classif\n",
    "\n",
    "from sklearn.metrics import precision_score, f1_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('display.max_rows',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "intrusion_df = pd.read_csv('data/cleaned_intrusion_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Variable Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# The columns of use\n",
    "\n",
    "num_cols = ['duration', 'src_bytes', 'dst_bytes', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins',\n",
    "            'num_compromised', 'num_root', 'count','num_file_creations', 'num_shells', 'num_access_files',\n",
    "            'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate','srv_rerror_rate', 'same_srv_rate', \n",
    "            'diff_srv_rate','srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count',\n",
    "            'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', \n",
    "            'dst_host_srv_diff_host_rate','dst_host_serror_rate', 'dst_host_srv_serror_rate',\n",
    "            'dst_host_rerror_rate', 'dst_host_srv_rerror_rate',\n",
    "           ]\n",
    "\n",
    "cat_cols = ['protocol_type = udp', 'protocol_type = tcp', 'protocol_type = icmp',  \n",
    "            'service = domain_u', 'service = http','service = smtp', 'service = ftp_data', 'service = ftp',\n",
    "            'service = eco_i', 'service = other', 'service = auth', 'service = ecr_i', 'service = IRC', \n",
    "            'service = X11', 'service = finger', 'service = time', 'service = telnet', \n",
    "            'service = ntp_u','service = tim_i', 'service = remote_job', 'service = link',\n",
    "            'service = urp_i', 'service = pop_3', 'service = tftp_u','service = imap4', \n",
    "            'service = nnsp', 'service = uucp', 'service = courier', 'service = login', \n",
    "            'service = icmp', 'service = domain', 'service = private',\n",
    "            'flag = SF', 'flag = RSTR', 'flag = S1', 'flag = REJ', 'flag = S3', \n",
    "            'flag = S2', 'flag = RSTOS0', 'flag = RSTO','flag = SH',\n",
    "            'logged_in', 'is_host_login', 'is_guest_login', 'root_shell', 'su_attempted',\n",
    "           ]\n",
    "\n",
    "target = 'target'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## $\\chi^2$ - Categorical Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Set Categorical data\n",
    "x_cat = intrusion_df[cat_cols]\n",
    "y = intrusion_df['target']\n",
    "\n",
    "# train test split rest and test\n",
    "x_cat_rest, x_cat_test, y_rest, y_test = TTS(x_cat, y, test_size=0.2, random_state=3)\n",
    "\n",
    "# TTS train and val\n",
    "x_cat_train, x_cat_val, y_train, y_val = TTS(x_cat_rest, y_rest, test_size=0.25, random_state =3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "selector_chi2 = SelectKBest(score_func = chi2, k = 21)\n",
    "selector_chi2.fit(x_cat_train,y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector_chi2.transform(x_cat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3231, 0.0029, 0.    , 0.0062, 0.    , 0.0031, 0.0239, 0.    ,\n",
       "       0.6733, 0.    , 0.6139, 0.    , 0.8446, 0.9219, 0.4818, 0.8265,\n",
       "       0.    , 0.6692, 0.    ,    nan, 0.9447, 0.7238, 0.8265, 0.9447,\n",
       "          nan,    nan, 0.    , 0.    ,    nan, 0.9219,    nan, 0.    ,\n",
       "       0.    , 0.7187, 0.8353, 0.0128, 0.9044, 0.8545, 0.9447, 0.9447,\n",
       "       0.    , 0.    , 0.    , 0.    , 0.    , 0.9044])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector_chi2.pvalues_.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.76275322e-01, 8.86252280e+00, 1.07973156e+03, 7.50308051e+00,\n",
       "       1.09095897e+02, 8.76640329e+00, 5.09935920e+00, 1.16680737e+02,\n",
       "       1.77729820e-01, 3.13077984e+01, 2.54585958e-01, 1.42882090e+03,\n",
       "       3.84280692e-02, 9.60701730e-03, 4.94761391e-01, 4.80350865e-02,\n",
       "       1.19679236e+03, 1.82533329e-01, 6.24543478e+02,            nan,\n",
       "       4.80350865e-03, 1.24891225e-01, 4.80350865e-02, 4.80350865e-03,\n",
       "                  nan,            nan, 2.08181159e+02, 2.08181159e+02,\n",
       "                  nan, 9.60701730e-03,            nan, 1.14071287e+03,\n",
       "       2.24339103e+01, 1.29694734e-01, 4.32315778e-02, 6.19935970e+00,\n",
       "       1.44105259e-02, 3.36245605e-02, 4.80350865e-03, 4.80350865e-03,\n",
       "       1.14499638e+04, 7.11338193e+01, 4.66908810e+02, 2.05902769e+01,\n",
       "       2.06058782e+03, 1.44105259e-02])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector_chi2.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        True, False,  True, False, False, False, False,  True, False,\n",
       "        True, False, False, False, False, False, False, False,  True,\n",
       "        True, False, False, False,  True,  True, False, False,  True,\n",
       "       False, False, False, False,  True,  True,  True,  True,  True,\n",
       "       False])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector_chi2.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['protocol_type = tcp', 'protocol_type = icmp', 'service = domain_u',\n",
       "       'service = http', 'service = smtp', 'service = ftp_data',\n",
       "       'service = ftp', 'service = other', 'service = ecr_i',\n",
       "       'service = telnet', 'service = tim_i', 'service = uucp',\n",
       "       'service = courier', 'service = private', 'flag = SF', 'flag = REJ',\n",
       "       'flag = SH', 'logged_in', 'is_host_login', 'is_guest_login',\n",
       "       'root_shell'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_chi2 = x_cat.iloc[:,selector_chi2.get_support(indices=True)]\n",
    "x_chi2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Exploring the NaN values\n",
    "\n",
    "For each column above that has been assiged a `NaN` $\\chi^2$ score and p value, the reason is that there exists exactly 1 record that is positive, while the rest are negative. Therefore these columns can be ignored for feature selection. See calculations below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "service = remote_job service = imap4 service = nnsp service = login service = domain\n"
     ]
    }
   ],
   "source": [
    "print(cat_cols[19], cat_cols[24], cat_cols[25], cat_cols[28], cat_cols[30]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.999979\n",
       "1.0    0.000021\n",
       "Name: service = remote_job, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intrusion_df['service = remote_job'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.999979\n",
       "1.0    0.000021\n",
       "Name: service = imap4, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intrusion_df['service = imap4'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.999979\n",
       "1.0    0.000021\n",
       "Name: service = nnsp, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intrusion_df['service = nnsp'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.999979\n",
       "1.0    0.000021\n",
       "Name: service = login, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intrusion_df['service = login'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.999979\n",
       "1.0    0.000021\n",
       "Name: service = domain, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intrusion_df['service = domain'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.010373"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.000021*len(intrusion_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## ANOVA - Numerical Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# Set Categorical data\n",
    "x_num = intrusion_df[num_cols]\n",
    "y = intrusion_df['target']\n",
    "\n",
    "# train test split\n",
    "x_num_rest, x_num_test, y_rest, y_test = TTS(x_num, y, test_size=0.2, random_state=3)\n",
    "\n",
    "x_num_train, x_num_val, y_train, y_val = TTS(x_num_rest, y_rest, test_size=0.25, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/learner/Desktop/KD_1000ml/Project6_Intrustion_Detection/project6_env/lib/python3.6/site-packages/sklearn/feature_selection/_univariate_selection.py:114: UserWarning: Features [4] are constant.\n",
      "  UserWarning)\n",
      "/home/learner/Desktop/KD_1000ml/Project6_Intrustion_Detection/project6_env/lib/python3.6/site-packages/sklearn/feature_selection/_univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SelectKBest(k=22, score_func=<function f_classif at 0x7f9a9b19b950>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_num_train_scale = scaler.fit_transform(x_num_train)\n",
    "\n",
    "# Use Select K Best\n",
    "selector_anova = SelectKBest(score_func= f_classif, k = 22)\n",
    "\n",
    "# fit the selector\n",
    "selector_anova.fit(x_num_train_scale, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.42 , 0.648, 0.767, 0.   ,   nan, 0.   , 0.   , 0.   , 0.006,\n",
       "       0.007, 0.   , 0.   , 0.   , 0.001, 0.   , 0.   , 0.153, 0.181,\n",
       "       0.991, 0.559, 0.672, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   ])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector_anova.pvalues_.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False,  True, False,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "       False, False, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector_anova.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wrong_fragment',\n",
       " 'hot',\n",
       " 'num_failed_logins',\n",
       " 'num_compromised',\n",
       " 'num_root',\n",
       " 'count',\n",
       " 'num_file_creations',\n",
       " 'num_shells',\n",
       " 'num_access_files',\n",
       " 'srv_count',\n",
       " 'serror_rate',\n",
       " 'srv_serror_rate',\n",
       " 'dst_host_count',\n",
       " 'dst_host_srv_count',\n",
       " 'dst_host_same_srv_rate',\n",
       " 'dst_host_diff_srv_rate',\n",
       " 'dst_host_same_src_port_rate',\n",
       " 'dst_host_srv_diff_host_rate',\n",
       " 'dst_host_serror_rate',\n",
       " 'dst_host_srv_serror_rate',\n",
       " 'dst_host_rerror_rate',\n",
       " 'dst_host_srv_rerror_rate']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_anova = x_num.iloc[:,selector_anova.get_support(indices=True)]\n",
    "list(x_anova.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Exploring Warnings\n",
    "\n",
    "We find the same problem as before for one of the columns. The other warning seems strange, but likely follows with the error from the `NaN`, given that the calculation comes in the line directly after the previous warning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    0.0\n",
       "2    0.0\n",
       "3    0.0\n",
       "4    0.0\n",
       "Name: urgent, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intrusion_df[num_cols].iloc[:,4].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.999958\n",
       "3.0    0.000021\n",
       "1.0    0.000021\n",
       "Name: urgent, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intrusion_df['urgent'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    0.0\n",
       "2    0.0\n",
       "3    0.0\n",
       "4    0.0\n",
       "Name: hot, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intrusion_df[num_cols].iloc[:,5].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0      0.995739\n",
       "4.0      0.001102\n",
       "1.0      0.000935\n",
       "5.0      0.000499\n",
       "2.0      0.000416\n",
       "6.0      0.000270\n",
       "7.0      0.000249\n",
       "3.0      0.000187\n",
       "18.0     0.000145\n",
       "19.0     0.000125\n",
       "22.0     0.000083\n",
       "24.0     0.000062\n",
       "14.0     0.000042\n",
       "30.0     0.000042\n",
       "10.0     0.000042\n",
       "11.0     0.000021\n",
       "101.0    0.000021\n",
       "15.0     0.000021\n",
       "Name: hot, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intrusion_df['hot'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to use:\n",
    "reduced_cat_cols = list(x_chi2.columns)\n",
    "reduced_num_cols = list(x_anova.columns)\n",
    "\n",
    "# set, train test split and scale\n",
    "# Set data\n",
    "x = intrusion_df[reduced_num_cols+reduced_cat_cols]\n",
    "y = intrusion_df['target']\n",
    "\n",
    "# train test split\n",
    "x_rest, x_test, y_rest, y_test = TTS(x,y,test_size=0.20,random_state=3)\n",
    "x_train, x_val, y_train, y_val = TTS(x_rest,y_rest,test_size=0.25,random_state=3)\n",
    "\n",
    "#reduced_cat_cols.remove('district_id')\n",
    "transformed_cols = reduced_num_cols+reduced_cat_cols\n",
    "\n",
    "# scale the numeric data\n",
    "ct = ColumnTransformer(\n",
    "            [(\"Num_Cols\", StandardScaler(), reduced_num_cols),\n",
    "             (\"Cat_Cols\", 'passthrough', reduced_cat_cols)\n",
    "             ])\n",
    "\n",
    "# Define scaled data as dataframes\n",
    "x_train_scale = pd.DataFrame(ct.fit_transform(x_train), columns=transformed_cols)\n",
    "x_val_scale = pd.DataFrame(ct.fit_transform(x_val), columns=transformed_cols)\n",
    "x_test_scale = pd.DataFrame(ct.fit_transform(x_test), columns=transformed_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scores(model, train_x, validation_x, train_y, validation_y):\n",
    "    '''\n",
    "    This function takes in a Classifier model that has previously been fit to a set of train data.\n",
    "    It then calculates the predicted classifications and outputs the recall, precision and f1 scores\n",
    "    for train and validation data sets\n",
    "    '''\n",
    "    y_train_pred = model.predict(train_x)\n",
    "    y_val_pred = model.predict(validation_x)\n",
    "    \n",
    "    train_prec = precision_score(train_y, y_train_pred)\n",
    "    val_prec = precision_score(validation_y, y_val_pred)\n",
    "    \n",
    "    train_f1 = f1_score(train_y, y_train_pred)\n",
    "    val_f1 = f1_score(validation_y, y_val_pred)\n",
    "    \n",
    "    train_recall = recall_score(train_y, y_train_pred)\n",
    "    val_recall = recall_score(validation_y, y_val_pred)\n",
    "    \n",
    "    print(f'''    Precision:\n",
    "    Train = {train_prec.round(3)}\n",
    "    Validation = {val_prec.round(3)}\n",
    "    \n",
    "    F1:\n",
    "    Train = {train_f1.round(3)}\n",
    "    Validation = {val_f1.round(3)}\n",
    "    \n",
    "    Recall:\n",
    "    Train = {train_recall.round(3)}\n",
    "    Validation = {val_recall.round(3)}    \n",
    "    ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "The grid search found some hot garbage. We should consider doing a more robust version of class balancing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search - LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramsl1 = {'penalty':['l1'],\n",
    "            'C':np.logspace(-2,4,7),\n",
    "            'solver':['newton-cg','lbfgs','sag','saga']\n",
    "           }\n",
    "paramsl2 = {'penalty':['l2'],\n",
    "            'C':np.logspace(-2,4,7),\n",
    "            'solver':['liblinear','saga']\n",
    "           }\n",
    "# params = [paramsl1, paramsl2]\n",
    "\n",
    "params_lr = {'penalty':['l2'],\n",
    "             'C':np.logspace(2,5,8),\n",
    "             'solver':['liblinear']\n",
    "            }\n",
    "scores = {'prec':'precision',\n",
    "          'F1':'f1'\n",
    "         }\n",
    "\n",
    "gs_lrc = GridSearchCV(LogisticRegression(class_weight='balanced',random_state=3,max_iter=200,n_jobs=-1), \n",
    "                            params_lr,\n",
    "                            scoring = scores,\n",
    "                            refit = 'prec',\n",
    "                            verbose = 1,\n",
    "                            n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  1.8min finished\n",
      "/home/learner/Desktop/KD_1000ml/Project6_Intrustion_Detection/project6_env/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 3.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=LogisticRegression(C=1.0, class_weight='balanced',\n",
       "                                          dual=False, fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=200, multi_class='auto',\n",
       "                                          n_jobs=-1, penalty='l2',\n",
       "                                          random_state=3, solver='lbfgs',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'C': array([   100.        ,    268.26957953,    719.685673  ,   1930.69772888,\n",
       "         5179.47467923,  13894.95494373,  37275.93720315, 100000.        ]),\n",
       "                         'penalty': ['l2'], 'solver': ['liblinear']},\n",
       "             pre_dispatch='2*n_jobs', refit='prec', return_train_score=False,\n",
       "             scoring={'F1': 'f1', 'prec': 'precision'}, verbose=1)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_lrc.fit(x_train_scale,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_prec</th>\n",
       "      <th>split1_test_prec</th>\n",
       "      <th>split2_test_prec</th>\n",
       "      <th>split3_test_prec</th>\n",
       "      <th>split4_test_prec</th>\n",
       "      <th>mean_test_prec</th>\n",
       "      <th>std_test_prec</th>\n",
       "      <th>rank_test_prec</th>\n",
       "      <th>split0_test_F1</th>\n",
       "      <th>split1_test_F1</th>\n",
       "      <th>split2_test_F1</th>\n",
       "      <th>split3_test_F1</th>\n",
       "      <th>split4_test_F1</th>\n",
       "      <th>mean_test_F1</th>\n",
       "      <th>std_test_F1</th>\n",
       "      <th>rank_test_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.209244</td>\n",
       "      <td>3.260351</td>\n",
       "      <td>0.012641</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>5179.47</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 5179.474679231213, 'penalty': 'l2', 'sol...</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.436364</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.376064</td>\n",
       "      <td>0.039550</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.578313</td>\n",
       "      <td>0.543210</td>\n",
       "      <td>0.495238</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.527352</td>\n",
       "      <td>0.030601</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.384768</td>\n",
       "      <td>2.466114</td>\n",
       "      <td>0.014908</td>\n",
       "      <td>0.005334</td>\n",
       "      <td>100000</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 100000.0, 'penalty': 'l2', 'solver': 'li...</td>\n",
       "      <td>0.346667</td>\n",
       "      <td>0.436364</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.373828</td>\n",
       "      <td>0.039697</td>\n",
       "      <td>2</td>\n",
       "      <td>0.504854</td>\n",
       "      <td>0.578313</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.485981</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.525147</td>\n",
       "      <td>0.031400</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.138232</td>\n",
       "      <td>4.260757</td>\n",
       "      <td>0.012932</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>37275.9</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 37275.93720314938, 'penalty': 'l2', 'sol...</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.329114</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.371387</td>\n",
       "      <td>0.037245</td>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.521757</td>\n",
       "      <td>0.029213</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.822868</td>\n",
       "      <td>2.966500</td>\n",
       "      <td>0.012253</td>\n",
       "      <td>0.001185</td>\n",
       "      <td>719.686</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 719.6856730011522, 'penalty': 'l2', 'sol...</td>\n",
       "      <td>0.329114</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.337662</td>\n",
       "      <td>0.356164</td>\n",
       "      <td>0.370302</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>4</td>\n",
       "      <td>0.485981</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.514851</td>\n",
       "      <td>0.521769</td>\n",
       "      <td>0.029960</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.879330</td>\n",
       "      <td>4.163402</td>\n",
       "      <td>0.014302</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>1930.7</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 1930.6977288832495, 'penalty': 'l2', 'so...</td>\n",
       "      <td>0.282828</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.415094</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.356164</td>\n",
       "      <td>0.363198</td>\n",
       "      <td>0.053605</td>\n",
       "      <td>5</td>\n",
       "      <td>0.440945</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.495238</td>\n",
       "      <td>0.514851</td>\n",
       "      <td>0.514493</td>\n",
       "      <td>0.045349</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  param_C  \\\n",
       "4       9.209244      3.260351         0.012641        0.001671  5179.47   \n",
       "7       8.384768      2.466114         0.014908        0.005334   100000   \n",
       "6      10.138232      4.260757         0.012932        0.000621  37275.9   \n",
       "2       6.822868      2.966500         0.012253        0.001185  719.686   \n",
       "3       8.879330      4.163402         0.014302        0.002555   1930.7   \n",
       "\n",
       "  param_penalty param_solver  \\\n",
       "4            l2    liblinear   \n",
       "7            l2    liblinear   \n",
       "6            l2    liblinear   \n",
       "2            l2    liblinear   \n",
       "3            l2    liblinear   \n",
       "\n",
       "                                              params  split0_test_prec  \\\n",
       "4  {'C': 5179.474679231213, 'penalty': 'l2', 'sol...          0.342105   \n",
       "7  {'C': 100000.0, 'penalty': 'l2', 'solver': 'li...          0.346667   \n",
       "6  {'C': 37275.93720314938, 'penalty': 'l2', 'sol...          0.342105   \n",
       "2  {'C': 719.6856730011522, 'penalty': 'l2', 'sol...          0.329114   \n",
       "3  {'C': 1930.6977288832495, 'penalty': 'l2', 'so...          0.282828   \n",
       "\n",
       "   split1_test_prec  split2_test_prec  split3_test_prec  split4_test_prec  \\\n",
       "4          0.436364          0.407407          0.333333          0.361111   \n",
       "7          0.436364          0.400000          0.325000          0.361111   \n",
       "6          0.428571          0.400000          0.329114          0.357143   \n",
       "2          0.428571          0.400000          0.337662          0.356164   \n",
       "3          0.428571          0.415094          0.333333          0.356164   \n",
       "\n",
       "   mean_test_prec  std_test_prec  rank_test_prec  split0_test_F1  \\\n",
       "4        0.376064       0.039550               1        0.500000   \n",
       "7        0.373828       0.039697               2        0.504854   \n",
       "6        0.371387       0.037245               3        0.500000   \n",
       "2        0.370302       0.038050               4        0.485981   \n",
       "3        0.363198       0.053605               5        0.440945   \n",
       "\n",
       "   split1_test_F1  split2_test_F1  split3_test_F1  split4_test_F1  \\\n",
       "4        0.578313        0.543210        0.495238        0.520000   \n",
       "7        0.578313        0.536585        0.485981        0.520000   \n",
       "6        0.571429        0.536585        0.490566        0.510204   \n",
       "2        0.571429        0.536585        0.500000        0.514851   \n",
       "3        0.571429        0.550000        0.495238        0.514851   \n",
       "\n",
       "   mean_test_F1  std_test_F1  rank_test_F1  \n",
       "4      0.527352     0.030601             1  \n",
       "7      0.525147     0.031400             2  \n",
       "6      0.521757     0.029213             4  \n",
       "2      0.521769     0.029960             3  \n",
       "3      0.514493     0.045349             5  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_lrc_results = pd.DataFrame(gs_lrc.cv_results_)\n",
    "gs_lrc_results.sort_values(by='rank_test_prec').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging Classifier - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search - Bagging - LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_bag_l1 = {'base_estimator__penalty':['l1'],\n",
    "                 'base_estimator__class_weight':['balanced'],\n",
    "                 'base_estimator__random_state':[3],\n",
    "                 'base_estimator__max_iter':[200],\n",
    "                 'base_estimator__n_jobs':[-1],\n",
    "                 'base_estimator__C':np.logspace(-2,4,7),\n",
    "                 'base_estimator__solver':['newton-cg','lbfgs','sag','saga'],\n",
    "                 'n_estimators':[10,50,100],\n",
    "                 'max_features':[0.6,0.8,1.0],\n",
    "                 'bootstrap_features':[True,False]\n",
    "                }\n",
    "params_bag_l2 = {'base_estimator__penalty':['l2'],\n",
    "                 'base_estimator__class_weight':['balanced'],\n",
    "                 'base_estimator__random_state':[3],\n",
    "                 'base_estimator__max_iter':[200],\n",
    "                 'base_estimator__n_jobs':[-1],\n",
    "                 'base_estimator__C':np.logspace(-2,4,7),\n",
    "                 'base_estimator__solver':['liblinear','saga'],\n",
    "                 'n_estimators':[10,50,100],\n",
    "                 'max_features':[0.6,0.8,1.0],\n",
    "                 'bootstrap_features':[True,False]\n",
    "                }\n",
    "params_bag_lr = [params_bag_l1, params_bag_l2]\n",
    "\n",
    "# params_lr = {'penalty':['l2'],\n",
    "#              'C':np.logspace(2,5,8),\n",
    "#              'solver':['liblinear']\n",
    "#             }\n",
    "scores = {'prec':'precision',\n",
    "          'Recall':'recall'\n",
    "         }\n",
    "\n",
    "gs_bag_lrc = RandomizedSearchCV(BaggingClassifier(LogisticRegression(),\n",
    "                                              n_jobs=-1,\n",
    "                                              random_state=3\n",
    "                                             ),\n",
    "                            params_bag_lr,\n",
    "                            scoring = scores,\n",
    "                            n_iter=50,     \n",
    "                            refit = 'prec',\n",
    "                            verbose = 1,\n",
    "                            n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 3 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "gs_bag_lrc.fit(x_train_scale,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_bag_lrc_results = pd.DataFrame(gs_lrc.cv_results_)\n",
    "gs_bag_lrc_results.sort_values(by='rank_test_prec').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "Slightly better than logistic regression but still pretty crap. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model from Grid Search\n",
    "dt_model = DecisionTreeClassifier(random_state=3,\n",
    "                                  class_weight='balanced',\n",
    "                                  criterion = 'entropy',\n",
    "                                  max_depth = 20,\n",
    "                                  min_samples_leaf=1,\n",
    "                                  min_samples_split=2,\n",
    "                                  min_impurity_decrease = 0.0\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight='balanced',\n",
       "                       criterion='entropy', max_depth=20, max_features=None,\n",
       "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       presort='deprecated', random_state=3, splitter='best')"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Precision:\n",
      "    Train = 0.986\n",
      "    Validation = 0.625\n",
      "    \n",
      "    F1:\n",
      "    Train = 0.993\n",
      "    Validation = 0.615\n",
      "    \n",
      "    Recall:\n",
      "    Train = 1.0\n",
      "    Validation = 0.606    \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print_scores(dt_model, x_train,x_val,y_train,y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search - DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dt = {'criterion':['entropy'],\n",
    "             'max_depth':[18,19,20,21],\n",
    "             'max_features':[None],\n",
    "             'min_samples_split':[2,4,6,8,10],\n",
    "             'min_samples_leaf':[1,2,3,4,5],\n",
    "             'min_impurity_decrease':[0.0,0.05],\n",
    "             'min_weight_fraction_leaf':[0.0,0.05]\n",
    "             }\n",
    "\n",
    "scores = {'prec':'precision',\n",
    "          'F1':'f1'\n",
    "         }\n",
    "\n",
    "gs_dtc = GridSearchCV(DecisionTreeClassifier(class_weight='balanced',random_state=3), \n",
    "                        params_dt,\n",
    "                        scoring = scores,\n",
    "                        refit = 'prec',\n",
    "                        verbose = 1,\n",
    "                        n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 400 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 382 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=-1)]: Done 882 tasks      | elapsed:   28.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1582 tasks      | elapsed:   51.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1995 out of 2000 | elapsed:  1.1min remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
       "                                              class_weight='balanced',\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort='deprecated',\n",
       "                                              random_state=3, splitter='best'),\n",
       "             i...cated', n_jobs=-1,\n",
       "             param_grid={'criterion': ['entropy'],\n",
       "                         'max_depth': [18, 19, 20, 21], 'max_features': [None],\n",
       "                         'min_impurity_decrease': [0.0, 0.05],\n",
       "                         'min_samples_leaf': [1, 2, 3, 4, 5],\n",
       "                         'min_samples_split': [2, 4, 6, 8, 10],\n",
       "                         'min_weight_fraction_leaf': [0.0, 0.05]},\n",
       "             pre_dispatch='2*n_jobs', refit='prec', return_train_score=False,\n",
       "             scoring={'F1': 'f1', 'prec': 'precision'}, verbose=1)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_dtc.fit(x_train_scale,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 19,\n",
       " 'max_features': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_dtc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_impurity_decrease</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_min_weight_fraction_leaf</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_prec</th>\n",
       "      <th>split1_test_prec</th>\n",
       "      <th>split2_test_prec</th>\n",
       "      <th>split3_test_prec</th>\n",
       "      <th>split4_test_prec</th>\n",
       "      <th>mean_test_prec</th>\n",
       "      <th>std_test_prec</th>\n",
       "      <th>rank_test_prec</th>\n",
       "      <th>split0_test_F1</th>\n",
       "      <th>split1_test_F1</th>\n",
       "      <th>split2_test_F1</th>\n",
       "      <th>split3_test_F1</th>\n",
       "      <th>split4_test_F1</th>\n",
       "      <th>mean_test_F1</th>\n",
       "      <th>std_test_F1</th>\n",
       "      <th>rank_test_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.088042</td>\n",
       "      <td>0.011410</td>\n",
       "      <td>0.011406</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>entropy</td>\n",
       "      <td>19</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 19, 'max...</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.806925</td>\n",
       "      <td>0.078933</td>\n",
       "      <td>1</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.796293</td>\n",
       "      <td>0.055655</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>0.085779</td>\n",
       "      <td>0.010372</td>\n",
       "      <td>0.010775</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>entropy</td>\n",
       "      <td>21</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 21, 'max...</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.806925</td>\n",
       "      <td>0.078933</td>\n",
       "      <td>1</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.796293</td>\n",
       "      <td>0.055655</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.084589</td>\n",
       "      <td>0.008084</td>\n",
       "      <td>0.011377</td>\n",
       "      <td>0.000975</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'max...</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.806925</td>\n",
       "      <td>0.078933</td>\n",
       "      <td>1</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.796293</td>\n",
       "      <td>0.055655</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.136441</td>\n",
       "      <td>0.028817</td>\n",
       "      <td>0.021758</td>\n",
       "      <td>0.012620</td>\n",
       "      <td>entropy</td>\n",
       "      <td>18</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 18, 'max...</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.792296</td>\n",
       "      <td>0.083143</td>\n",
       "      <td>4</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.792215</td>\n",
       "      <td>0.053947</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>0.085977</td>\n",
       "      <td>0.010413</td>\n",
       "      <td>0.011425</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>entropy</td>\n",
       "      <td>21</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 21, 'max...</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.756367</td>\n",
       "      <td>0.056722</td>\n",
       "      <td>5</td>\n",
       "      <td>0.836364</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.774684</td>\n",
       "      <td>0.043083</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "100       0.088042      0.011410         0.011406        0.000695   \n",
       "300       0.085779      0.010372         0.010775        0.001223   \n",
       "200       0.084589      0.008084         0.011377        0.000975   \n",
       "0         0.136441      0.028817         0.021758        0.012620   \n",
       "302       0.085977      0.010413         0.011425        0.000507   \n",
       "\n",
       "    param_criterion param_max_depth param_max_features  \\\n",
       "100         entropy              19               None   \n",
       "300         entropy              21               None   \n",
       "200         entropy              20               None   \n",
       "0           entropy              18               None   \n",
       "302         entropy              21               None   \n",
       "\n",
       "    param_min_impurity_decrease param_min_samples_leaf  \\\n",
       "100                           0                      1   \n",
       "300                           0                      1   \n",
       "200                           0                      1   \n",
       "0                             0                      1   \n",
       "302                           0                      1   \n",
       "\n",
       "    param_min_samples_split param_min_weight_fraction_leaf  \\\n",
       "100                       2                              0   \n",
       "300                       2                              0   \n",
       "200                       2                              0   \n",
       "0                         2                              0   \n",
       "302                       4                              0   \n",
       "\n",
       "                                                params  split0_test_prec  \\\n",
       "100  {'criterion': 'entropy', 'max_depth': 19, 'max...          0.923077   \n",
       "300  {'criterion': 'entropy', 'max_depth': 21, 'max...          0.923077   \n",
       "200  {'criterion': 'entropy', 'max_depth': 20, 'max...          0.923077   \n",
       "0    {'criterion': 'entropy', 'max_depth': 18, 'max...          0.923077   \n",
       "302  {'criterion': 'entropy', 'max_depth': 21, 'max...          0.851852   \n",
       "\n",
       "     split1_test_prec  split2_test_prec  split3_test_prec  split4_test_prec  \\\n",
       "100          0.833333          0.793103          0.677419          0.807692   \n",
       "300          0.833333          0.793103          0.677419          0.807692   \n",
       "200          0.833333          0.793103          0.677419          0.807692   \n",
       "0            0.833333          0.741935          0.677419          0.785714   \n",
       "302          0.769231          0.750000          0.677419          0.733333   \n",
       "\n",
       "     mean_test_prec  std_test_prec  rank_test_prec  split0_test_F1  \\\n",
       "100        0.806925       0.078933               1        0.888889   \n",
       "300        0.806925       0.078933               1        0.888889   \n",
       "200        0.806925       0.078933               1        0.888889   \n",
       "0          0.792296       0.083143               4        0.888889   \n",
       "302        0.756367       0.056722               5        0.836364   \n",
       "\n",
       "     split1_test_F1  split2_test_F1  split3_test_F1  split4_test_F1  \\\n",
       "100        0.769231        0.821429        0.724138        0.777778   \n",
       "300        0.769231        0.821429        0.724138        0.777778   \n",
       "200        0.769231        0.821429        0.724138        0.777778   \n",
       "0          0.769231        0.793103        0.724138        0.785714   \n",
       "302        0.740741        0.813559        0.724138        0.758621   \n",
       "\n",
       "     mean_test_F1  std_test_F1  rank_test_F1  \n",
       "100      0.796293     0.055655             1  \n",
       "300      0.796293     0.055655             1  \n",
       "200      0.796293     0.055655             1  \n",
       "0        0.792215     0.053947             4  \n",
       "302      0.774684     0.043083             5  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_dtc_results = pd.DataFrame(gs_dtc.cv_results_)\n",
    "gs_dtc_results.sort_values(by='rank_test_prec').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 150,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': None,\n",
       " 'max_depth': 20,\n",
       " 'criterion': 'gini'}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(class_weight='balanced',\n",
    "                                  random_state=3,\n",
    "                                  n_estimators=150,\n",
    "                                  min_samples_leaf=1,\n",
    "                                  min_samples_split=2,\n",
    "                                  max_features=None,\n",
    "                                  max_depth=20,\n",
    "                                  criterion='gini'\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=20, max_features=None,\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=150,\n",
       "                       n_jobs=None, oob_score=False, random_state=3, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Precision:\n",
      "    Train = 1.0\n",
      "    Validation = 0.87\n",
      "    \n",
      "    F1:\n",
      "    Train = 1.0\n",
      "    Validation = 0.714\n",
      "    \n",
      "    Recall:\n",
      "    Train = 1.0\n",
      "    Validation = 0.606    \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print_scores(rf_model, x_train, x_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Grid Search - RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "params_rf = {'criterion':['gini'],\n",
    "          'n_estimators':[150,200,250],\n",
    "          'max_depth':[18,19,20],\n",
    "          'max_features':[None],\n",
    "          'min_samples_split':[2,4,6],\n",
    "          'min_samples_leaf':[1,2,3],\n",
    "          #'min_impurity_decrease':[0.0,0.05,0.1],\n",
    "          #'min_weight_fraction_leaf':[0.0,0.05,0.1]\n",
    "         }\n",
    "scores = {'prec':'precision',\n",
    "          'F1':'f1'\n",
    "         }\n",
    "gs_rfc = RandomizedSearchCV(RandomForestClassifier(class_weight='balanced',random_state=3, n_jobs=-1), \n",
    "                            params_rf,\n",
    "                            scoring = scores,\n",
    "                            n_iter=100,\n",
    "                            refit = 'prec',\n",
    "                            verbose = 1,\n",
    "                            n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/learner/Desktop/KD_1000ml/Project6_Intrustion_Detection/project6_env/lib/python3.6/site-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 81 is smaller than n_iter=100. Running 81 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 194 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed: 18.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score=nan,\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    ccp_alpha=0.0,\n",
       "                                                    class_weight='balanced',\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    max_samples=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators=1...\n",
       "                                                    warm_start=False),\n",
       "                   iid='deprecated', n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'criterion': ['gini'],\n",
       "                                        'max_depth': [18, 19, 20],\n",
       "                                        'max_features': [None],\n",
       "                                        'min_samples_leaf': [1, 2, 3],\n",
       "                                        'min_samples_split': [2, 4, 6],\n",
       "                                        'n_estimators': [150, 200, 250]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit='prec',\n",
       "                   return_train_score=False,\n",
       "                   scoring={'F1': 'f1', 'prec': 'precision'}, verbose=1)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_rfc.fit(x_train_scale,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_prec</th>\n",
       "      <th>split1_test_prec</th>\n",
       "      <th>split2_test_prec</th>\n",
       "      <th>split3_test_prec</th>\n",
       "      <th>split4_test_prec</th>\n",
       "      <th>mean_test_prec</th>\n",
       "      <th>std_test_prec</th>\n",
       "      <th>rank_test_prec</th>\n",
       "      <th>split0_test_F1</th>\n",
       "      <th>split1_test_F1</th>\n",
       "      <th>split2_test_F1</th>\n",
       "      <th>split3_test_F1</th>\n",
       "      <th>split4_test_F1</th>\n",
       "      <th>mean_test_F1</th>\n",
       "      <th>std_test_F1</th>\n",
       "      <th>rank_test_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>10.136246</td>\n",
       "      <td>0.583543</td>\n",
       "      <td>0.580342</td>\n",
       "      <td>0.149497</td>\n",
       "      <td>250</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'n_estimators': 250, 'min_samples_split': 4, ...</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.918502</td>\n",
       "      <td>0.052029</td>\n",
       "      <td>4</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.777868</td>\n",
       "      <td>0.047520</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>9.844708</td>\n",
       "      <td>0.464870</td>\n",
       "      <td>0.478826</td>\n",
       "      <td>0.043480</td>\n",
       "      <td>250</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'n_estimators': 250, 'min_samples_split': 2, ...</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.918502</td>\n",
       "      <td>0.052029</td>\n",
       "      <td>4</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.777868</td>\n",
       "      <td>0.047520</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>5.664063</td>\n",
       "      <td>0.315840</td>\n",
       "      <td>0.255237</td>\n",
       "      <td>0.008975</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'n_estimators': 150, 'min_samples_split': 2, ...</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.941905</td>\n",
       "      <td>0.036688</td>\n",
       "      <td>1</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.777760</td>\n",
       "      <td>0.047189</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>6.074953</td>\n",
       "      <td>0.625996</td>\n",
       "      <td>0.336723</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'n_estimators': 150, 'min_samples_split': 2, ...</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.910597</td>\n",
       "      <td>0.055095</td>\n",
       "      <td>6</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.774859</td>\n",
       "      <td>0.047358</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>5.749916</td>\n",
       "      <td>0.475423</td>\n",
       "      <td>0.303976</td>\n",
       "      <td>0.054270</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'n_estimators': 150, 'min_samples_split': 4, ...</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.910597</td>\n",
       "      <td>0.055095</td>\n",
       "      <td>6</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.774859</td>\n",
       "      <td>0.047358</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "68      10.136246      0.583543         0.580342        0.149497   \n",
       "65       9.844708      0.464870         0.478826        0.043480   \n",
       "54       5.664063      0.315840         0.255237        0.008975   \n",
       "63       6.074953      0.625996         0.336723        0.043669   \n",
       "66       5.749916      0.475423         0.303976        0.054270   \n",
       "\n",
       "   param_n_estimators param_min_samples_split param_min_samples_leaf  \\\n",
       "68                250                       4                      2   \n",
       "65                250                       2                      2   \n",
       "54                150                       2                      1   \n",
       "63                150                       2                      2   \n",
       "66                150                       4                      2   \n",
       "\n",
       "   param_max_features param_max_depth param_criterion  \\\n",
       "68               None              20            gini   \n",
       "65               None              20            gini   \n",
       "54               None              20            gini   \n",
       "63               None              20            gini   \n",
       "66               None              20            gini   \n",
       "\n",
       "                                               params  split0_test_prec  \\\n",
       "68  {'n_estimators': 250, 'min_samples_split': 4, ...          0.954545   \n",
       "65  {'n_estimators': 250, 'min_samples_split': 2, ...          0.954545   \n",
       "54  {'n_estimators': 150, 'min_samples_split': 2, ...          0.952381   \n",
       "63  {'n_estimators': 150, 'min_samples_split': 2, ...          0.913043   \n",
       "66  {'n_estimators': 150, 'min_samples_split': 4, ...          0.913043   \n",
       "\n",
       "    split1_test_prec  split2_test_prec  split3_test_prec  split4_test_prec  \\\n",
       "68               1.0          0.904762          0.869565          0.863636   \n",
       "65               1.0          0.904762          0.869565          0.863636   \n",
       "54               1.0          0.900000          0.952381          0.904762   \n",
       "63               1.0          0.904762          0.909091          0.826087   \n",
       "66               1.0          0.904762          0.909091          0.826087   \n",
       "\n",
       "    mean_test_prec  std_test_prec  rank_test_prec  split0_test_F1  \\\n",
       "68        0.918502       0.052029               4        0.840000   \n",
       "65        0.918502       0.052029               4        0.840000   \n",
       "54        0.941905       0.036688               1        0.816327   \n",
       "63        0.910597       0.055095               6        0.823529   \n",
       "66        0.910597       0.055095               6        0.823529   \n",
       "\n",
       "    split1_test_F1  split2_test_F1  split3_test_F1  split4_test_F1  \\\n",
       "68        0.697674        0.791667        0.800000        0.760000   \n",
       "65        0.697674        0.791667        0.800000        0.760000   \n",
       "54        0.697674        0.765957        0.833333        0.775510   \n",
       "63        0.697674        0.791667        0.816327        0.745098   \n",
       "66        0.697674        0.791667        0.816327        0.745098   \n",
       "\n",
       "    mean_test_F1  std_test_F1  rank_test_F1  \n",
       "68      0.777868     0.047520             1  \n",
       "65      0.777868     0.047520             1  \n",
       "54      0.777760     0.047189             3  \n",
       "63      0.774859     0.047358             4  \n",
       "66      0.774859     0.047358             4  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_rfc_results = pd.DataFrame(gs_rfc.cv_results_)\n",
    "gs_rfc_results.sort_values(by='rank_test_F1').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
